{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6641c183",
   "metadata": {},
   "source": [
    "# Part 2 : Preparation data and model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a151a",
   "metadata": {},
   "source": [
    "## Preparation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import torch\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import  GPT2Tokenizer, GPT2LMHeadModel, DataCollatorForLanguageModeling, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79ef49c",
   "metadata": {},
   "source": [
    "## Device setting (GPU Activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6132802",
   "metadata": {},
   "source": [
    "Explain why we install CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ae184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available. \n",
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available. \\nUsing GPU\")\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    print(\"GPU is not available. \\nUsing CPU\")\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61de3a5",
   "metadata": {},
   "source": [
    "## File Upload and Dataframe manipulation 🗃️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb05ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "query",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "c5de1aa9-e0a2-4b14-a3bf-82bea013c4e0",
       "rows": [
        [
         "0",
         "SELECT count(*) FROM head WHERE age  >  56",
         "How many heads of the departments are older than 56 ?"
        ],
        [
         "1",
         "SELECT name ,  born_state ,  age FROM head ORDER BY age",
         "List the name, born state and age of the heads of departments ordered by age."
        ],
        [
         "2",
         "SELECT creation ,  name ,  budget_in_billions FROM department",
         "List the creation year, name and budget of each department."
        ],
        [
         "3",
         "SELECT max(budget_in_billions) ,  min(budget_in_billions) FROM department",
         "What are the maximum and minimum budget of the departments?"
        ],
        [
         "4",
         "SELECT avg(num_employees) FROM department WHERE ranking BETWEEN 10 AND 15",
         "What is the average number of employees of the departments whose rank is between 10 and 15?"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT count(*) FROM head WHERE age  &gt;  56</td>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT name ,  born_state ,  age FROM head ORD...</td>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT creation ,  name ,  budget_in_billions ...</td>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT max(budget_in_billions) ,  min(budget_i...</td>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT avg(num_employees) FROM department WHER...</td>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0         SELECT count(*) FROM head WHERE age  >  56   \n",
       "1  SELECT name ,  born_state ,  age FROM head ORD...   \n",
       "2  SELECT creation ,  name ,  budget_in_billions ...   \n",
       "3  SELECT max(budget_in_billions) ,  min(budget_i...   \n",
       "4  SELECT avg(num_employees) FROM department WHER...   \n",
       "\n",
       "                                            question  \n",
       "0  How many heads of the departments are older th...  \n",
       "1  List the name, born state and age of the heads...  \n",
       "2  List the creation year, name and budget of eac...  \n",
       "3  What are the maximum and minimum budget of the...  \n",
       "4  What is the average number of employees of the...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/query_question_sql_copilot.csv\", sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7283bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "f7000747-28cd-4aa5-82d5-dcd5389b421e",
       "rows": [
        [
         "query",
         "0"
        ],
        [
         "question",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "query       0\n",
       "question    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2939803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88688 entries, 0 to 88687\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   query     88688 non-null  object\n",
      " 1   question  88688 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d689b496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88688 entries, 0 to 88687\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   query     88688 non-null  object\n",
      " 1   question  88688 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.astype(str)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e789475",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51fecaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query', 'question', '__index_level_0__'],\n",
       "    num_rows: 79819\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30720de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query', 'question', '__index_level_0__'],\n",
       "    num_rows: 8869\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = Dataset.from_pandas(test_df)\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837caf2f",
   "metadata": {},
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af699271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the tokenizer and model\n",
    "checkpoint = 'distilgpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT2 doesn't have a pad token by default\n",
    "model = GPT2LMHeadModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8ed5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    max_length = 512\n",
    "    inputs = [doc for doc in examples[\"query\"]]\n",
    "    model_inputs = tokenizer(inputs, padding='max_length', truncation=True, max_length=max_length)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"question\"], padding='max_length', truncation=True, max_length=max_length)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "337c1709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/79819 [00:00<?, ? examples/s]c:\\Users\\ksimotabudjifupa\\Documents\\Personnel\\Data_science_projects\\sql_copilot\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3959: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 79819/79819 [00:28<00:00, 2777.78 examples/s]\n",
      "Map: 100%|██████████| 8869/8869 [00:03<00:00, 2476.27 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = train_ds.map(preprocess_function, batched=True, batch_size=2000,\n",
    "                               remove_columns=['question', 'query','__index_level_0__'])\n",
    "\n",
    "tokenized_test = test_ds.map(preprocess_function, batched=True, batch_size=2000,\n",
    "                               remove_columns=['question', 'query','__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating Data Collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./gpt2_text2sql',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=tokenized_train,         # training dataset\n",
    "    eval_dataset=tokenized_test             # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f336303",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    num_steps = 500\n",
    "    batch_size = 8\n",
    "    data_size = len(tokenized_train)\n",
    "    num_batches = data_size // batch_size\n",
    "    num_epochs = 2\n",
    "    # Suggest hyperparameters to optimize\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-7, 5e-6)\n",
    "    weight_decay = trial.suggest_uniform(\"weight_decay\", 0.01, 0.1)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    warmup_ratio = trial.suggest_uniform(\"warmup_ratio\", 0.0, 0.3)\n",
    "    focal_loss_alpha = trial.suggest_uniform(\"focal_loss_alpha\", 0.5, 1.0)\n",
    "    focal_loss_gamma = trial.suggest_int(\"focal_loss_gamma\", 1, 3)\n",
    "\n",
    "    # Define TrainingArguments with suggested hyperparameters\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./models/finetuned_distilgpt2\",\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        save_steps=100,\n",
    "        save_total_limit=10,\n",
    "        dataloader_num_workers=0,\n",
    "        logging_strategy=\"steps\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=10,\n",
    "        use_cpu=False,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    # Define Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "        args=training_args,                  # training arguments, defined above\n",
    "        train_dataset=tokenized_train,         # training dataset\n",
    "        eval_dataset=tokenized_test             # evaluation dataset\n",
    "    )\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    eval_result = trainer.evaluate()\n",
    "    # Return the metric to minimize (or maximize)\n",
    "    return eval_result[\"eval_loss\"]\n",
    "\n",
    "\n",
    "# Create a study object\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "# Optimize the objective function\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
